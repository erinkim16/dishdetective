{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-2rPvWLwqH74"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # For plotting\n",
        "import numpy as np              # Linear algebra library\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/311/final_final_fr_fr.csv')\n",
        "\n",
        "# Print unique values for each column\n",
        "for column in df.columns:\n",
        "    print(f\"Unique values in {column}: {df[column].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdq4HT95rdnW",
        "outputId": "fa80aeb6-6259-4aa7-f138-7916f2a46062"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in id: [716549 715742 727333 606874 505318 605771 606929 609789 644623 626792\n",
            " 714863 602805 602526 497421 389328 289931 620148 387155 516975 630825\n",
            " 614043 521125 627780 492744 618747 607815 601609 602657 616449 501893\n",
            " 507448 606556 724326 616945 630962 715814 502799 605278 388888 519548\n",
            " 405521 607410 715795 625326 627220 634964 722500 602824 618355 611097\n",
            " 634328 607160 728522 718570 714598 601950 612478 501416 629710 502610\n",
            " 603476 600957 713423 722431 633234 148179 715845 632153 606552 738409\n",
            " 612096 743537 632896 605207 617542 719554 627427 411315 631507 627798\n",
            " 712093 627488 626493 601363 712898 603398 631012 601848 612131 408630\n",
            " 632091 601122 602871 520828 514199 389697 714430 612567 744468 502722\n",
            " 519681 631125 606119 627252 616568 603838 719735 608062 608704 520383\n",
            " 603793 603933 605519 524803 629712 627505 526131 607065 500077 633350\n",
            " 601945 629878 712766 603664 840827 604897 525422 602560 738379 622023\n",
            " 604770 608318 626757 745297 627599 520037 632189 627636 295428 228777\n",
            " 609278 614089 607517 714607 716650 497695 496858 608688 604386 628559\n",
            " 715152 604110 629010 605254 628990 625295 603415 635533 630389 714901\n",
            " 629792 629025 524441 389109 631216 738875 634669 409940 399605 721831\n",
            " 835223 712938 395712 603388 617774 289440 714503 714893 601094 618150\n",
            " 607944 629844 626482 609257 717921 181851 629041 604062 716749 633143\n",
            " 743828 520861 517019 626779 611716 193195 627530 626479 624540 625315\n",
            " 601941 723968 715806 720045 713585 611188 606726 629142 634825 613409\n",
            " 633224 738850 500470  13183 627169 229041 496344 409723 630949 413014\n",
            " 310438 627430 526510 390823 717116 712143 612538 627539 603812 740568\n",
            " 712702 519638 627800 406863 726962 628077 601693 517096 606821 455047\n",
            " 625576 747734 517064 387330 746750 629285 743488 523710 635179 313562\n",
            " 712670 635627 524485 632320 633520 606905 393424 618333 628558 613776\n",
            " 317214 628093 411781 525567 634455 498848 638838 411253 410165 608554\n",
            " 602394 743623  87783 632431 744091 519570 744484 508149 524992 413570\n",
            " 306207 634468 522205   5978 742611 631198 606150 313577 629700 630928\n",
            " 607286 607609 522890 630227 603607 617029 617462 633001 634690 630198\n",
            " 520507 635065 613209 605452  24137 518809 634646 508156 632909 414734\n",
            " 630250 411810 214145 628986 211158 507382 522877 635024 602845 519822\n",
            " 600849 605148 631600 716142 525853 835124 634764 630117 631531 714062\n",
            " 629156 498563 625319 723931 526497 630999  97339 631909 625349 632299\n",
            " 616634 616836 609116 626789 504599 632684 522967 632893 632156 603582\n",
            " 626754 298481 631583 718026 616713 602533 522345 629758 631496 491374\n",
            " 632051 409930 632975 407221 204508 618700 627792 712054 631881 716188\n",
            " 628744 604132 629807 741428 633024 631221 601983 603007 601217 629221\n",
            " 634705 630070 630006 629072 630044 626026 520303 630972 630948 626778\n",
            " 631181 633541 630098 629959 633097 605290 629869 632868 209691 600915\n",
            " 525420 414710 629985 523128 727410 616457 206487  68949 419835 745732\n",
            " 543739 410380 385307 634566 625818 631164 603130 229211 626849 634650\n",
            " 632125 626812 631109 716766 494103 628102 634683 517774 408898 603189\n",
            " 606857 523080 631014 503957 524890 717411 525311 630967 604969 524480\n",
            " 630121 629615 634977 630823 632228 504548 522477 523461 312640 854745\n",
            " 711854 739254 621555 602482 630416 505458 296589 604826 387820 603612\n",
            " 712252 742226 712771 746466 601737 631902 312320 519986 626771 407257\n",
            " 626883 727339 631448 634885 619932 601986 631141 631069 634508 206744\n",
            " 498213 627496 629659 630190 401586 629263 631678 411681 518733 630378\n",
            " 631142 519976 604991 522483 629723 387522 613484 388729 494373 630977\n",
            " 621982 605537 607073 624443 718089 622727 609617 526064 609179 627638\n",
            " 411117 634430 631711 606010 631436 633712 609556 520090 602234 741592\n",
            " 628547 501513 630929 617379 617310 495424 622787 631716 741658 620745\n",
            " 611932 635602 619892 529289 630738 524766 522148 601547 631046  66222\n",
            " 603182 632117 630209 413395 386750 617178 630128 628736]\n",
            "Unique values in Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex): [3 4 2 5 1]\n",
            "Unique values in Q2: How many ingredients would you expect this food item to contain?: ['6' '2' '5' '3' '4' '9' '10' '8' '7' '21' '11' '15' '1' '13' '12' 'none'\n",
            " '20' '25' '17' '14' '18' '23']\n",
            "Unique values in Q3: In what setting would you expect this food to be served? Please check all that apply: ['Week day lunch,At a party,Late night snack'\n",
            " 'Week day lunch,Week day dinner,Weekend lunch,Weekend dinner'\n",
            " 'Week day lunch,Week day dinner,Weekend lunch,Weekend dinner,At a party,Late night snack'\n",
            " 'Week day lunch,Week day dinner,Weekend lunch,Weekend dinner,At a party'\n",
            " 'Week day lunch'\n",
            " 'Week day dinner,Weekend lunch,Weekend dinner,At a party,Late night snack'\n",
            " 'Weekend dinner,At a party' 'Weekend lunch,Weekend dinner,At a party'\n",
            " 'Weekend lunch,Weekend dinner,At a party,Late night snack'\n",
            " 'Week day dinner,At a party'\n",
            " 'Week day dinner,Weekend dinner,At a party,Late night snack'\n",
            " 'Week day lunch,Week day dinner,Weekend dinner,At a party'\n",
            " 'Weekend dinner,At a party,Late night snack' 'At a party'\n",
            " 'Week day lunch,Weekend lunch,At a party'\n",
            " 'Week day lunch,Week day dinner,At a party'\n",
            " 'Week day lunch,Weekend dinner,At a party,Late night snack'\n",
            " 'Week day dinner,At a party,Late night snack'\n",
            " 'Week day dinner,Weekend dinner,At a party'\n",
            " 'Week day lunch,Week day dinner,Weekend lunch,At a party'\n",
            " 'Week day lunch,Week day dinner,At a party,Late night snack'\n",
            " 'Weekend lunch,At a party,Late night snack'\n",
            " 'Week day lunch,Late night snack'\n",
            " 'Week day lunch,Week day dinner,Weekend lunch,At a party,Late night snack'\n",
            " 'Week day lunch,Weekend lunch,At a party,Late night snack'\n",
            " 'Week day lunch,Week day dinner,Weekend dinner,At a party,Late night snack'\n",
            " 'Week day lunch,At a party' 'Week day lunch,Weekend lunch'\n",
            " 'Week day dinner,Weekend lunch,Weekend dinner,At a party'\n",
            " 'Weekend lunch,At a party' 'Weekend lunch,Weekend dinner'\n",
            " 'Week day lunch,Weekend dinner,At a party' 'Week day dinner'\n",
            " 'Week day lunch,Weekend lunch,Weekend dinner,At a party,Late night snack'\n",
            " 'Week day dinner,Weekend dinner'\n",
            " 'Week day dinner,Weekend lunch,At a party,Late night snack'\n",
            " 'Week day lunch,Week day dinner,Weekend lunch,Late night snack'\n",
            " 'Week day lunch,Week day dinner,Late night snack'\n",
            " 'Week day lunch,Week day dinner,Weekend lunch,Weekend dinner,Late night snack'\n",
            " 'Weekend lunch' 'Week day lunch,Weekend lunch,Late night snack'\n",
            " 'Week day lunch,Week day dinner'\n",
            " 'Week day lunch,Week day dinner,Weekend lunch'\n",
            " 'Week day lunch,Weekend dinner'\n",
            " 'Week day dinner,Weekend dinner,Late night snack'\n",
            " 'Week day lunch,Weekend dinner,Late night snack'\n",
            " 'Weekend dinner,Late night snack'\n",
            " 'Week day lunch,Weekend lunch,Weekend dinner'\n",
            " 'Week day lunch,Weekend lunch,Weekend dinner,Late night snack'\n",
            " 'Week day dinner,Weekend lunch,Weekend dinner'\n",
            " 'Week day lunch,Week day dinner,Weekend dinner' 'Weekend dinner'\n",
            " 'Week day lunch,Weekend lunch,Weekend dinner,At a party'\n",
            " 'Week day dinner,Weekend lunch,At a party' 'At a party,Late night snack'\n",
            " 'Week day dinner,Weekend lunch' 'Week day dinner,Late night snack'\n",
            " 'Late night snack' 'Weekend lunch,Weekend dinner,Late night snack'\n",
            " 'Week day dinner,Weekend lunch,Weekend dinner,Late night snack']\n",
            "Unique values in Q4: How much would you expect to pay for one serving of this food item?: ['5.0' '10.0' '3.0' '15.0' '1.0' '20.0' '4.0' '12.0' '6.0' '30.0' '7.0'\n",
            " '8.0' '22.5' '11.5' '13.0' '6.5' '35.0' '4.99' '18.0' '2.0' '2.5' '3.5'\n",
            " '17.0' '22.0' '5.5' '16.0' '25.0' '14.0' '3.75' '4.5' '2.29' '64.0' '7.5'\n",
            " '9.0' '8.5' '11.0' '12.5' 'none' '5.99' '16.99' '57.0' '7.25' '65.0'\n",
            " '23.0' '50.0' '17.5' '45.0' '13.5' '80.0' '28.0' '14.5' '6.96' '62.0'\n",
            " '14.99' '4.29' '19.0' '16.5' '24.0' '3.95' '3.45' '4.25' '2.99' '3.99'\n",
            " '18.5' '11.99' '9.99' '16.98' '9.5' '10.5' '12.36' '13.99' '100.0' '1.5'\n",
            " '40.0' '20.99' '10.99' '12.79' '27.5' '11.02' '1.49' '32.5']\n",
            "Unique values in Q5: What movie do you think of when thinking of this food item?: ['cloudy with a chance of meatballs'\n",
            " 'all sort of american young boy movies' 'action movie' 'mamma mia' 'none'\n",
            " 'dragon' 'rick and morty' 'home alone' 'the big lebowski' 'spiderman'\n",
            " 'goodfellas' 'a goofy movie the disney movie' 'dead silence' 'la la land'\n",
            " 'harry potter' 'transformer' 'teenage mutant ninja turtles'\n",
            " 'high school musical 3' 'despicable me' 'toy story' 'the godfather'\n",
            " 'pizza' 'fast furious' 'garfield' 'spiderman no way home' 'ratatouille'\n",
            " 'five nights at freddys' 'the avengers' 'back to the future' 'godfather'\n",
            " 'mystic pizza' 'futurama' 'iron man' 'life of pi' 'any american movie'\n",
            " 'king kong' 'grown ups' 'deadpool' 'cloudy with a chance of meatball'\n",
            " 'whiplash' 'inside out' 'superbad' 'stranger things' 'air bud'\n",
            " 'a quiet place day one 2024' 'finding nemo' 'my cousin vinny'\n",
            " 'eat pray love' 'comedy' 'star wars' 'the dark knight' 'pulp fiction'\n",
            " 'fast and furious' 'the truman show' 'breaking bad' 'interstellar'\n",
            " 'rush hour' 'shrek' 'scooby doo' 'back to the future 2'\n",
            " 'princess diaries the apology scene' 'walle' 'spy kids 3d' 'squid game'\n",
            " 'running man' 'recep ivedik 2' 'venom' 'moneyball'\n",
            " 'hangover or any teen party movies which features a lot of sweet stuff'\n",
            " 'coraline' 'life if pi' 'james bond 007' 'the goofy movie'\n",
            " 'a quiet place 2' 'carryon' 'set it up' 'green book' 'cars'\n",
            " 'relaxing comedy' 'high school musical' 'zootopia' 'mario movie'\n",
            " '30 minutes or less' '21 jump street' 'free guy' 'harry poter' 'soul'\n",
            " 'life is beautiful' 'the wicked' 'harold kumar go to white castle'\n",
            " 'lord of the rings' 'the hangover' 'breaking bad not a movie'\n",
            " 'little italy' 'everything everywhere all at once' 'barbie' 'hitman'\n",
            " 'liquorice pizza' 'the dictator' 'anjaana anjaani' 'hawkeye' 'argo'\n",
            " 'transformers' 'aladdin' 'the invisible guest' 'titanic' '1001 nights'\n",
            " 'shawarma legend' 'dangal' 'spiderman into the spiderverse'\n",
            " 'slumdog millionaire' 'cleopatra' 'the kite runner' '2012' 'the boys'\n",
            " 'mission impossible' 'black hawk down' 'dictator' 'kungfu panda'\n",
            " 'alladin' 'how to lose a guy in 10 days' 'babylon' 'prince of egypt'\n",
            " 'borat' 'harold and kumar' 'gossip girl' 'monty python'\n",
            " 'khabi khushi khabi gham' 'mission impossible dead reckoning part one'\n",
            " '3 idiots' 'dune' 'parasite' 'batman the dark knight' 'the mummy'\n",
            " 'taxi driver' 'comedy movie' 'you dont mess with the zohan'\n",
            " 'spider man spider verse' 'gladiator' 'any bollywood movie'\n",
            " 'scott pilgrim vs the world' 'son of babylon'\n",
            " 'cloudy with a chance of meatballs again shawarmas dont appear in that though but hey its food'\n",
            " 'bad boys' 'the social network' 'documenary' 'chef' 'minions'\n",
            " 'the big sick' 'jurassic park' 'wicked' 'the avengers 1' 'the avenger'\n",
            " 'arcane' 'bahen' 'legend of shawama' 'forest gump' 'john wick'\n",
            " 'scott pilgrim' 'good will hunting' 'fight club' 'shawarma bowl' 'drive'\n",
            " 'lion king' 'captain of america' 'spirited away' 'japanese movies'\n",
            " 'cartoon movie' 'johnny english' 'karate kid' 'drange' 'kung fu panda'\n",
            " 'wolverine' 'jiro dreams of sushi' 'kill bill' 'your name'\n",
            " 'once upon a time in hollywood'\n",
            " 'the lord of the rings the fellowship of the ring' 'shark tale'\n",
            " 'bullet train' 'japanese' 'isle of dogs' 'little forest a japanese film'\n",
            " 'doraemon' 'naruto' 'jaws' 'the end of evangelion' 'midnight diner'\n",
            " 'anime' 'crazy rich asians' 'the perfect storm' 'the karate kid'\n",
            " 'the pacific' 'weathering with you'\n",
            " 'eternal sunshine of the spotless mind' 'cars 2' 'my neighbour totoro'\n",
            " 'oldboy' 'the proposal' 'rurouni kenshin' 'gone girl' 'my hero academia'\n",
            " 'food wars' 'your name 2016' 'liz and the blue bird' 'spirited away 2001'\n",
            " 'frozen' 'seven samurai' 'the boy and the heron' 'howls moving castle'\n",
            " 'suits' 'john wick 4' 'ghibli movies' 'bladerunner' 'a silent voice 2016'\n",
            " 'monsters inc' 'jiro dreams of sush' 'inception' 'big big wolf'\n",
            " 'wolf of wall street' 'romance movie' 'wolf of wallstreet' 'godzilla'\n",
            " 'scary movie 4 2006' 'monster house' 'the big short' 'the little mermaid'\n",
            " 'lost in translation' 'pirates of the carribeans'\n",
            " 'jiro dreams of sushi east side sushi finding nemo' 'monster inc'\n",
            " 'spirit away' 'gran turismo' 'short movie because i eat it fast'\n",
            " 'the breakfast club' 'ponyo' 'samurai jack' 'mean girls' 'girls trip'\n",
            " 'my neighbor totoro' 'anime i guess' 'passengers2016' 'madagascar'\n",
            " 'koe no katachi' 'talented' 'crayon shinchan the movie'\n",
            " 'memoirs of a geisha' 'masterchef' 'monster' 'the last samurai' 'suzume'\n",
            " 'detective conan' 'big hero 6' 'snowpiercer' 'yakuza'\n",
            " 'wizards of waverly place movie'\n",
            " 'teenage mutant ninja turtles the turtles are famous for their love of pizza'\n",
            " 'spiderman across the spiderverse' 'saving private ryan' 'mr deeds'\n",
            " 'documentary' 'murder mystery' 'the super mario bros movie' 'the ritual'\n",
            " 'breakaway' 'uncle grandpa' 'captain america' 'pirates of the caribbean'\n",
            " 'the boy and the herron' 'the grinch' 'the lego movie'\n",
            " 'futurama benders big score' 'the italian job'\n",
            " 'back to the future part 2'\n",
            " 'any kind really probably something more relaxed for leisure'\n",
            " 'american pie' 'friday' 'this is the end'\n",
            " 'ready player one there is pacman inside and pizza looks like one'\n",
            " 'the gentlemen' 'gilmore girls' 'happy gilmore' 'ratatoullie'\n",
            " 'back in action' 'die hard' 'neverending story' 'maze runner'\n",
            " 'diary of a wimpy kid rodrick rules' 'malena' 'anchorman' 'friends'\n",
            " 'terminator' 'men in black' 'the davinci code' 'crazy stupid love'\n",
            " 'the hunger games' 'luca' 'any movie set in new york' 'cartoons'\n",
            " 'waynes world' 'scific type' 'do the right thing' 'space jam' 'spongebob'\n",
            " 'diary of a wimpy kid' 'step brothers' 'horror movie'\n",
            " 'the princess diaries' 'oppenheimer'\n",
            " 'i think of movies that ive watch with either my friends or my siblings'\n",
            " 'the barbie movie' 'pursuit of happyness' 'middle east movie' 'drishyam'\n",
            " 'us' 'shrek2' 'nosferatu' 'alien' 'indiana jones' 'angry birds'\n",
            " 'the road to fallujah' 'kingdom of heaven' 'lawrence of arabia'\n",
            " 'time of happiness' 'middle eastern movies' 'hangover' 'coco' '11sep'\n",
            " '13 hours' 'murder on the orient express' 'three idiots' 'shazam'\n",
            " 'the lion king' 'aladdin idk' 'deadpool and wolverine' 'mulan' 'mandoob'\n",
            " 'the prince of egypt' 'indian movie' 'south park the end of obesity'\n",
            " 'yeh jawaani hai deewani' 'dabba' 'cheech chong' 'shawshank redemption'\n",
            " 'mad max' 'taken 2' 'ferris buellers day off' 'the dora movie'\n",
            " 'the whale' 'chinese zodiac' 'sonic the hedgehog' 'bollywood'\n",
            " 'middle eastern movie' 'burnt' 'rush hour 3' 'scary movie' 'the menu'\n",
            " 'the emoji movie' 'rush hour 2' 'a silent voice' 'pokemon' 'house md'\n",
            " 'the fast and the furious tokyo drift' 'who am i jackie chan'\n",
            " 'japanese movies food documentaries' 'kodoku no gurume' 'gi joe'\n",
            " 'penguins of madagascar' 'japanese movie' 'shrek3' 'aquaman' '47 ronin'\n",
            " 'barbie 2021' 'pengnuins of madagascar' '9' 'james bond' 'wags'\n",
            " 'notting hill' 'made in abyss dawn of the deep soul' 'meitantei konan'\n",
            " 'shangchi' 'billions tv show' 'madagascar 2' 'ip man' 'django unchained'\n",
            " 'the samurai' 'shangchi and the legend of the ten rings' 'karate kid ii'\n",
            " '7 samurai' 'casablanca' 'pacific rim' 'train to busan' 'love hard'\n",
            " 'shogun' 'the room' 'fallen angels' 'totoro'\n",
            " 'shinchan the movie chounouryoku daikessen tobe tobe temakizushi'\n",
            " 'shanghai noon' 'one piece' 'turning red' 'blade runner'\n",
            " 'fast furious tokyo drift' 'lucy' 'hunger' 'the intern' 'the meg 2018'\n",
            " 'rush hour series' 'ultraman rising' 'pearl harbour' 'good time'\n",
            " 'who am i 2005' 'memory of a geisha' 'last samurai' 'city hunter'\n",
            " 'alitathe warrior' 'haikyu' 'the spy next door' 'shang chi'\n",
            " 'breakfast club' 'heretic' 'crayon shinchan' 'anime movie' 'cars 3'\n",
            " 'east side sushi' 'shang chi the legend of ten rings'\n",
            " 'chandni chowk to china' 'midnight dinner' 'kikis delivery service'\n",
            " 'romantic movies' 'one piece film gold']\n",
            "Unique values in Q6: What drink would you pair with this food item?: ['coke' 'soda' 'ice tea' 'lemonade' 'red wine' 'sprite' 'water' 'soup'\n",
            " 'root beer' '7up' 'none' 'orange fanta' 'mountain dew' 'diet pepsi'\n",
            " 'juice' 'dr pepper' 'soft drink' 'pop' 'ginger ale' 'milk' 'boba'\n",
            " 'lemon tea' 'ayran' 'lassi' 'carbonated drink' 'the avengers' 'jarritos'\n",
            " 'oolong tea' 'sake' 'green tea' 'calpis' 'barley tea' 'hot tea'\n",
            " 'fish sauce' 'matcha' 'champagne' 'crush' 'pineapple fanta' 'canada dry'\n",
            " 'gatorade' 'sprindrift' 'martini cocktail' 'smoothie' 'laban' 'yogurt'\n",
            " 'coffee' 'barbican' 'leban' 'fruit tea' 'dairy' 'powerade' 'ramune'\n",
            " 'mango pulp' 'diet brisk' 'yakult' 'saporo' 'soy sauce' 'baijiu'\n",
            " 'any tea']\n",
            "Unique values in Q7: When you think about this food item, who does it remind you of?: ['Friends' 'Friends,Teachers,Strangers' 'Siblings,Friends,Teachers'\n",
            " 'Siblings,Friends' 'none' 'Parents,Siblings,Friends' 'Parents,Friends'\n",
            " 'Friends,Strangers' 'Parents,Siblings,Friends,Strangers' 'Parents'\n",
            " 'Parents,Siblings,Friends,Teachers' 'Friends,Teachers' 'Teachers'\n",
            " 'Parents,Friends,Teachers' 'Siblings,Teachers' 'Teachers,Strangers'\n",
            " 'Siblings' 'Siblings,Friends,Strangers' 'Parents,Siblings,Teachers'\n",
            " 'Parents,Siblings' 'Strangers' 'Siblings,Friends,Teachers,Strangers'\n",
            " 'Parents,Friends,Teachers,Strangers'\n",
            " 'Parents,Siblings,Friends,Teachers,Strangers' 'Parents,Teachers'\n",
            " 'Parents,Friends,Strangers' 'Parents,Siblings,Strangers'\n",
            " 'Parents,Strangers' 'Siblings,Strangers' 'Parents,Teachers,Strangers']\n",
            "Unique values in Q8: How much hot sauce would you add to this food item?: ['A little (mild)' 'none' 'A moderate amount (medium)'\n",
            " 'I will have some of this food item with my hot sauce' 'A lot (hot)']\n",
            "Unique values in Label: ['Pizza' 'Shawarma' 'Sushi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorized_one_hot(answers, attributes, attribute_to_index):\n",
        "    indices_list = [\n",
        "        [attribute_to_index[attr] for attr in ans if attr in attribute_to_index]\n",
        "        for ans in answers\n",
        "    ]\n",
        "\n",
        "    # Create a 2D array filled with zeros\n",
        "    one_hot_matrix = np.zeros((len(answers), len(attributes)), dtype=int)\n",
        "\n",
        "    # Set appropriate positions to 1\n",
        "    for i, indices in enumerate(indices_list):\n",
        "        one_hot_matrix[i, indices] = 1\n",
        "\n",
        "    return one_hot_matrix\n",
        "\n",
        "\n",
        "\n",
        "q1 = \"\"\"Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex)\"\"\"\n",
        "q2='Q2: How many ingredients would you expect this food item to contain?'\n",
        "q3='Q3: In what setting would you expect this food to be served? Please check all that apply'\n",
        "q4='Q4: How much would you expect to pay for one serving of this food item?'\n",
        "q5='Q5: What movie do you think of when thinking of this food item?'\n",
        "q6='Q6: What drink would you pair with this food item?'\n",
        "q7='Q7: When you think about this food item, who does it remind you of?'\n",
        "q8='Q8: How much hot sauce would you add to this food item?'\n",
        "t='Label'\n",
        "\n",
        "df[q2] = df[q2].replace(\"none\", '0').astype(str)\n",
        "df[q4] = df[q4].replace(\"none\", '0').astype(str)\n",
        "\n",
        "# one hot codings\n",
        "q1_options = [1,2,3,4,5]\n",
        "q3_options = ['none','Week day lunch','Week day dinner','Weekend lunch','Weekend dinner','At a party', 'Late night snack']\n",
        "q7_options = ['Parents','Siblings','Friends', 'Teachers', 'Strangers' , 'none']\n",
        "q8_options = ['I will have some of this food item with my hot sauce', 'A lot (hot)', 'A moderate amount (medium)', 'A little (mild)', 'none']\n",
        "\n",
        "# one_hot = pd.get_dummies(df[q3], prefix=\"HotSauce\")\n",
        "# print(one_hot)\n",
        "\n",
        "q3_attribute_to_index = {attr: idx for idx, attr in enumerate(q3_options)}\n",
        "q3_ans = df[q3].astype(str).tolist()\n",
        "q3_answers = [ans.split(\",\") for ans in q3_ans]\n",
        "q3_hot = vectorized_one_hot(q3_answers, q3_options, q3_attribute_to_index)\n",
        "print(q3_hot, '\\n')\n",
        "\n",
        "q7_attribute_to_index = {attr: idx for idx, attr in enumerate(q7_options)}\n",
        "q7_ans = df[q7].astype(str).tolist()\n",
        "q7_answers = [ans.split(\",\") for ans in q7_ans]\n",
        "q7_hot = vectorized_one_hot(q7_answers, q7_options, q7_attribute_to_index)\n",
        "print(q7_hot, '\\n')\n",
        "\n",
        "q8_attribute_to_index = {attr: idx for idx, attr in enumerate(q8_options)}\n",
        "q8_ans = df[q8].astype(str).tolist()\n",
        "q8_answers = [ans.split(\",\") for ans in q8_ans]\n",
        "q8_hot = vectorized_one_hot(q8_answers, q8_options, q8_attribute_to_index)\n",
        "print(q8_hot, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSAafZU1j3y",
        "outputId": "ded425be-d96a-4830-ee44-0e2132af65ef"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 ... 0 1 1]\n",
            " [0 1 0 ... 0 1 1]\n",
            " [0 1 1 ... 1 0 0]\n",
            " ...\n",
            " [0 1 0 ... 0 1 0]\n",
            " [0 1 0 ... 0 0 1]\n",
            " [0 1 1 ... 1 0 1]] \n",
            "\n",
            "[[0 0 1 0 0 0]\n",
            " [0 0 1 1 1 0]\n",
            " [0 0 1 0 0 0]\n",
            " ...\n",
            " [1 0 0 0 0 0]\n",
            " [0 1 1 0 1 0]\n",
            " [1 1 1 0 1 0]] \n",
            "\n",
            "[[0 0 0 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " ...\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.preprocessing import (StandardScaler, LabelEncoder,\n",
        "                                 MultiLabelBinarizer, OneHotEncoder,\n",
        "                                 FunctionTransformer)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define vectorized_one_hot function\n",
        "def vectorized_one_hot(answers, options, attribute_to_index):\n",
        "    num_samples = len(answers)\n",
        "    num_attributes = len(options)\n",
        "    one_hot_matrix = np.zeros((num_samples, num_attributes))\n",
        "\n",
        "    for i, ans_list in enumerate(answers):\n",
        "        for ans in ans_list:\n",
        "            ans = ans.strip()\n",
        "            if ans in attribute_to_index:\n",
        "                one_hot_matrix[i, attribute_to_index[ans]] = 1\n",
        "    return one_hot_matrix\n",
        "\n",
        "# Question definitions\n",
        "q1 = \"Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex)\"\n",
        "q2 = \"Q2: How many ingredients would you expect this food item to contain?\"\n",
        "q3 = \"Q3: In what setting would you expect this food to be served? Please check all that apply\"\n",
        "q4 = \"Q4: How much would you expect to pay for one serving of this food item?\"\n",
        "q5 = \"Q5: What movie do you think of when thinking of this food item?\"\n",
        "q6 = \"Q6: What drink would you pair with this food item?\"\n",
        "q7 = \"Q7: When you think about this food item, who does it remind you of?\"\n",
        "q8 = \"Q8: How much hot sauce would you add to this food item?\"\n",
        "t = \"Label\"\n",
        "\n",
        "# Data cleaning\n",
        "df[q2] = df[q2].replace(\"none\", '0').astype(str)\n",
        "df[q4] = df[q4].replace(\"none\", '0').astype(str)\n",
        "\n",
        "# Define options for categorical columns\n",
        "q1_options = [1,2,3,4,5]\n",
        "q3_options = ['none','Week day lunch','Week day dinner','Weekend lunch','Weekend dinner','At a party', 'Late night snack']\n",
        "q7_options = ['Parents','Siblings','Friends', 'Teachers', 'Strangers' , 'none']\n",
        "q8_options = ['I will have some of this food item with my hot sauce', 'A lot (hot)', 'A moderate amount (medium)', 'A little (mild)', 'none']\n",
        "\n",
        "# Create attribute to index mappings\n",
        "q3_attribute_to_index = {attr: idx for idx, attr in enumerate(q3_options)}\n",
        "q7_attribute_to_index = {attr: idx for idx, attr in enumerate(q7_options)}\n",
        "q8_attribute_to_index = {attr: idx for idx, attr in enumerate(q8_options)}\n",
        "\n",
        "# Manual feature engineering approach\n",
        "df[q2] = pd.to_numeric(df[q2])\n",
        "df[q1] = pd.to_numeric(df[q1])\n",
        "df[q4] = pd.to_numeric(df[q4])\n",
        "\n",
        "numerical_features = df[[q1, q2, q4]].values\n",
        "\n",
        "# Multi-hot encoding\n",
        "q3_hot = vectorized_one_hot([ans.split(\",\") for ans in df[q3].astype(str).tolist()], q3_options, q3_attribute_to_index)\n",
        "q7_hot = vectorized_one_hot([ans.split(\",\") for ans in df[q7].astype(str).tolist()], q7_options, q7_attribute_to_index)\n",
        "q8_hot = vectorized_one_hot([ans.split(\",\") for ans in df[q8].astype(str).tolist()], q8_options, q8_attribute_to_index)\n",
        "\n",
        "# Frequency encoding\n",
        "q5_encoded = df[q5].map(df[q5].value_counts(normalize=True)).to_frame()\n",
        "q6_encoded = df[q6].map(df[q6].value_counts(normalize=True)).to_frame()\n",
        "\n",
        "# Combine features\n",
        "X = np.hstack([\n",
        "    numerical_features,\n",
        "    q3_hot,\n",
        "    q7_hot,\n",
        "    q8_hot,\n",
        "    q5_encoded,\n",
        "    q6_encoded\n",
        "])\n",
        "\n",
        "# Sparse version\n",
        "X_sparse = sparse.hstack([\n",
        "    sparse.csr_matrix(numerical_features),\n",
        "    sparse.csr_matrix(q3_hot),\n",
        "    sparse.csr_matrix(q7_hot),\n",
        "    sparse.csr_matrix(q8_hot),\n",
        "    sparse.csr_matrix(q5_encoded),\n",
        "    sparse.csr_matrix(q6_encoded)\n",
        "])\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df[\"Label\"])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Manual model\n",
        "manual_model = LogisticRegression(\n",
        "    multi_class=\"multinomial\",\n",
        "    solver=\"lbfgs\",\n",
        "    max_iter=1000\n",
        ")\n",
        "manual_model.fit(X_train, y_train)\n",
        "print(\"Manual Feature Engineering Accuracy:\", manual_model.score(X_test, y_test))\n",
        "\n",
        "# Pipeline approach\n",
        "def create_vectorized_one_hot(options, attribute_to_index):\n",
        "    def transformer(X):\n",
        "        return vectorized_one_hot([ans.split(\",\") for ans in X.astype(str)], options, attribute_to_index)\n",
        "    return FunctionTransformer(transformer)\n",
        "\n",
        "def create_frequency_encoder(col):\n",
        "    def transformer(X):\n",
        "        return X.map(col.value_counts(normalize=True)).values.reshape(-1, 1)\n",
        "    return FunctionTransformer(transformer)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', ColumnTransformer([\n",
        "        ('num', StandardScaler(), [q1, q2, q4]),\n",
        "        ('q3', create_vectorized_one_hot(q3_options, q3_attribute_to_index), [q3]),\n",
        "        ('q7', create_vectorized_one_hot(q7_options, q7_attribute_to_index), [q7]),\n",
        "        ('q8', create_vectorized_one_hot(q8_options, q8_attribute_to_index), [q8]),\n",
        "        ('q5', create_frequency_encoder(df[q5]), [q5]),\n",
        "        ('q6', create_frequency_encoder(df[q6]), [q6])\n",
        "    ], remainder='drop')),\n",
        "    ('classifier', LogisticRegression(\n",
        "        multi_class='multinomial',\n",
        "        solver='lbfgs',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Fit pipeline\n",
        "pipeline.fit(df, y)\n",
        "\n",
        "# Evaluate pipeline\n",
        "print(\"Pipeline Accuracy:\", pipeline.score(df, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "kl3eEJLaxeRK",
        "outputId": "415c5f9f-54bc-4fdd-e04f-dd024518dd66"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Feature Engineering Accuracy: 0.790273556231003\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "the first argument must be callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-cc20dc5f8c60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;31m# Fit pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;31m# Evaluate pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_empty_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m         result = self._call_func_on_transformers(\n\u001b[0m\u001b[1;32m   1002\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    908\u001b[0m                 )\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_function_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \"\"\"\n\u001b[1;32m    259\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0moutput_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dense\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_function_transformer.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_args\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkw_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-cc20dc5f8c60>\u001b[0m in \u001b[0;36mtransformer\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_frequency_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10461\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10463\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10465\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: the first argument must be callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "df[q2] = pd.to_numeric(df[q2])\n",
        "df[q1] = pd.to_numeric(df[q1])\n",
        "df[q4] = pd.to_numeric(df[q4])\n",
        "\n",
        "\n",
        "numerical_features = df[[q1, q2, q4]].values  # or .to_numpy()\n",
        "\n",
        "# Replace each movie/drink name with its frequency in the dataset\n",
        "q5_encoded = df[q5].map(df[q5].value_counts(normalize=True)).to_frame()\n",
        "q6_encoded = df[q6].map(df[q6].value_counts(normalize=True)).to_frame()\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "# Assuming you already have:\n",
        "# q3_hot, q7_hot, q8_hot (from multi-hot encoding)\n",
        "# numerical_features, q5_encoded, q6_encoded\n",
        "\n",
        "X = np.hstack([\n",
        "    numerical_features,\n",
        "    q3_hot,          # Multi-hot for Q3\n",
        "    q7_hot,          # Multi-hot for Q7\n",
        "    q8_hot,          # Multi-hot for Q8\n",
        "    q5_encoded,      # Encoded Q5 (movie)\n",
        "    q6_encoded       # Encoded Q6 (drink)\n",
        "])\n",
        "\n",
        "# If using sparse matrices (for memory efficiency):\n",
        "X_sparse = sparse.hstack([\n",
        "    sparse.csr_matrix(numerical_features),\n",
        "    sparse.csr_matrix(q3_hot),\n",
        "    sparse.csr_matrix(q7_hot),\n",
        "    sparse.csr_matrix(q8_hot),\n",
        "    sparse.csr_matrix(q5_encoded),\n",
        "    sparse.csr_matrix(q6_encoded)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df[\"Label\"])  # e.g., Pizza  0, Shawarma  1, Sushi  2\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Train model (multinomial for multi-class)\n",
        "model = LogisticRegression(\n",
        "    multi_class=\"multinomial\",  # For >2 classes\n",
        "    solver=\"lbfgs\",            # Good for small datasets\n",
        "    max_iter=1000              # Increase if convergence warning appears\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", model.score(X_test, y_test))\n",
        "\n",
        "# First, import all required modules\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MultiLabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), [q1, q2, q4]),\n",
        "        (\"cat_q3\", MultiLabelBinarizer(classes=q3_options), q3),\n",
        "        (\"cat_q7\", MultiLabelBinarizer(classes=q7_options), q7),\n",
        "        (\"cat_q8\", MultiLabelBinarizer(classes=q8_options), q8),\n",
        "        (\"text_q5\", OneHotEncoder(handle_unknown=\"ignore\"), [q5]),\n",
        "        (\"text_q6\", OneHotEncoder(handle_unknown=\"ignore\"), [q6])\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\"))\n",
        "])\n",
        "\n",
        "pipeline.fit(df, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "MKNbSv6K4mAC",
        "outputId": "87bfd9ac-d020-4e26-810d-3ea204a01bfa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8115501519756839\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MultiLabelBinarizer.fit_transform() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a51aabb74293>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m ])\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_empty_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m         result = self._call_func_on_transformers(\n\u001b[0m\u001b[1;32m   1002\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    908\u001b[0m                 )\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MultiLabelBinarizer.fit_transform() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First ensure all required imports are at the top\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.preprocessing import (StandardScaler, LabelEncoder,\n",
        "                                 MultiLabelBinarizer, OneHotEncoder)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Your existing data preparation code\n",
        "df[q2] = pd.to_numeric(df[q2])\n",
        "df[q1] = pd.to_numeric(df[q1])\n",
        "df[q4] = pd.to_numeric(df[q4])\n",
        "\n",
        "numerical_features = df[[q1, q2, q4]].values\n",
        "\n",
        "# Frequency encoding for Q5 and Q6\n",
        "q5_encoded = df[q5].map(df[q5].value_counts(normalize=True)).to_frame()\n",
        "q6_encoded = df[q6].map(df[q6].value_counts(normalize=True)).to_frame()\n",
        "\n",
        "# Your multi-hot encoding (assuming vectorized_one_hot is defined)\n",
        "q3_hot = vectorized_one_hot([ans.split(\",\") for ans in df[q3].tolist()], q3_options, q3_attribute_to_index)\n",
        "q7_hot = vectorized_one_hot([ans.split(\",\") for ans in df[q7].tolist()], q7_options, q7_attribute_to_index)\n",
        "q8_hot = vectorized_one_hot([ans.split(\",\") for ans in df[q8].tolist()], q8_options, q8_attribute_to_index)\n",
        "\n",
        "# Combine features\n",
        "X = np.hstack([\n",
        "    numerical_features,\n",
        "    q3_hot,\n",
        "    q7_hot,\n",
        "    q8_hot,\n",
        "    q5_encoded,\n",
        "    q6_encoded\n",
        "])\n",
        "\n",
        "# Sparse version - FIXED PARENTHESIS HERE\n",
        "X_sparse = sparse.hstack([\n",
        "    sparse.csr_matrix(numerical_features),\n",
        "    sparse.csr_matrix(q3_hot),\n",
        "    sparse.csr_matrix(q7_hot),\n",
        "    sparse.csr_matrix(q8_hot),\n",
        "    sparse.csr_matrix(q5_encoded),\n",
        "    sparse.csr_matrix(q6_encoded)\n",
        "])\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df[\"Label\"])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Your existing model\n",
        "manual_model = LogisticRegression(\n",
        "    multi_class=\"multinomial\",\n",
        "    solver=\"lbfgs\",\n",
        "    max_iter=1000\n",
        ")\n",
        "manual_model.fit(X_train, y_train)\n",
        "print(\"Manual Feature Engineering Accuracy:\", manual_model.score(X_test, y_test))\n",
        "\n",
        "# Pipeline version (alternative approach)\n",
        "# Define a custom wrapper for your vectorized_one_hot function\n",
        "class VectorizedOneHotEncoder:\n",
        "    def __init__(self, options, attribute_to_index):\n",
        "        self.options = options\n",
        "        self.attribute_to_index = attribute_to_index\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        answers = [ans.split(\",\") for ans in X]\n",
        "        return vectorized_one_hot(answers, self.options, self.attribute_to_index)\n",
        "\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', ColumnTransformer([\n",
        "        ('num', StandardScaler(), [q1, q2, q4]),\n",
        "        ('q3', VectorizedOneHotEncoder(q3_options, q3_attribute_to_index), q3),\n",
        "        ('q7', VectorizedOneHotEncoder(q7_options, q7_attribute_to_index), q7),\n",
        "        ('q8', VectorizedOneHotEncoder(q8_options, q8_attribute_to_index), q8),\n",
        "        ('q5', Pipeline([\n",
        "            ('freq_enc', FunctionTransformer(lambda x: x.map(x.value_counts(normalize=True)))),\n",
        "            ('reshape', FunctionTransformer(lambda x: x.values.reshape(-1, 1)))\n",
        "        ])),\n",
        "        ('q6', Pipeline([\n",
        "            ('freq_enc', FunctionTransformer(lambda x: x.map(x.value_counts(normalize=True)))),\n",
        "            ('reshape', FunctionTransformer(lambda x: x.values.reshape(-1, 1)))\n",
        "        ]))\n",
        "    ])),\n",
        "    ('classifier', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000))\n",
        "])\n",
        "\n",
        "# Fit pipeline\n",
        "pipeline.fit(df, y)\n",
        "\n",
        "# Evaluate pipeline\n",
        "print(\"Pipeline Accuracy:\", pipeline.score(df, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "zMniowUR9dhg",
        "outputId": "db9752de-d6e0-48c0-ecd6-e8787a6ee1ac"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Feature Engineering Accuracy: 0.790273556231003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-6d048d44b33f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m# Fit pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# Evaluate pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# set n_features_in_ attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_transformers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# validate names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.preprocessing import (StandardScaler, LabelEncoder,\n",
        "                                 FunctionTransformer)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Your vectorized_one_hot function\n",
        "def vectorized_one_hot(answers, options, attribute_to_index):\n",
        "    num_samples = len(answers)\n",
        "    num_attributes = len(options)\n",
        "    one_hot_matrix = np.zeros((num_samples, num_attributes))\n",
        "\n",
        "    for i, ans_list in enumerate(answers):\n",
        "        for ans in ans_list:\n",
        "            ans = ans.strip()\n",
        "            if ans in attribute_to_index:\n",
        "                one_hot_matrix[i, attribute_to_index[ans]] = 1\n",
        "    return one_hot_matrix\n",
        "\n",
        "# Define question columns\n",
        "questions = [q1, q2, q3, q4, q5, q6, q7, q8] = [\n",
        "    \"Q1: From a scale 1 to 5, how complex is it to make this food? (Where 1 is the most simple, and 5 is the most complex)\",\n",
        "    \"Q2: How many ingredients would you expect this food item to contain?\",\n",
        "    \"Q3: In what setting would you expect this food to be served? Please check all that apply\",\n",
        "    \"Q4: How much would you expect to pay for one serving of this food item?\",\n",
        "    \"Q5: What movie do you think of when thinking of this food item?\",\n",
        "    \"Q6: What drink would you pair with this food item?\",\n",
        "    \"Q7: When you think about this food item, who does it remind you of?\",\n",
        "    \"Q8: How much hot sauce would you add to this food item?\"\n",
        "]\n",
        "t = 'Label'\n",
        "\n",
        "\n",
        "# Data cleaning\n",
        "df[q2] = df[q2].replace(\"none\", '0').astype(float)\n",
        "df[q4] = df[q4].replace(\"none\", '0').astype(float)\n",
        "df[q1] = pd.to_numeric(df[q1])\n",
        "\n",
        "# Define options for categorical columns\n",
        "q3_options = ['none','Week day lunch','Week day dinner','Weekend lunch',\n",
        "             'Weekend dinner','At a party', 'Late night snack']\n",
        "q7_options = ['Parents','Siblings','Friends', 'Teachers', 'Strangers', 'none']\n",
        "q8_options = ['I will have some of this food item with my hot sauce',\n",
        "             'A lot (hot)', 'A moderate amount (medium)', 'A little (mild)', 'none']\n",
        "\n",
        "# Create attribute to index mappings\n",
        "q3_attribute_to_index = {attr: idx for idx, attr in enumerate(q3_options)}\n",
        "q7_attribute_to_index = {attr: idx for idx, attr in enumerate(q7_options)}\n",
        "q8_attribute_to_index = {attr: idx for idx, attr in enumerate(q8_options)}\n",
        "\n",
        "# Manual feature engineering approach\n",
        "numerical_features = df[[q1, q2, q4]].values\n",
        "\n",
        "# Convert DataFrame columns to lists before splitting\n",
        "q3_answers = [ans.split(\",\") for ans in df[q3].astype(str).tolist()]\n",
        "q7_answers = [ans.split(\",\") for ans in df[q7].astype(str).tolist()]\n",
        "q8_answers = [ans.split(\",\") for ans in df[q8].astype(str).tolist()]\n",
        "\n",
        "q3_hot = vectorized_one_hot(q3_answers, q3_options, q3_attribute_to_index)\n",
        "q7_hot = vectorized_one_hot(q7_answers, q7_options, q7_attribute_to_index)\n",
        "q8_hot = vectorized_one_hot(q8_answers, q8_options, q8_attribute_to_index)\n",
        "\n",
        "# Frequency encoding\n",
        "q5_encoded = df[q5].map(df[q5].value_counts(normalize=True)).values.reshape(-1, 1)\n",
        "q6_encoded = df[q6].map(df[q6].value_counts(normalize=True)).values.reshape(-1, 1)\n",
        "\n",
        "# Combine features\n",
        "X = np.hstack([\n",
        "    numerical_features,\n",
        "    q3_hot,\n",
        "    q7_hot,\n",
        "    q8_hot,\n",
        "    q5_encoded,\n",
        "    q6_encoded\n",
        "])\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df[t])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Manual model\n",
        "manual_model = LogisticRegression(\n",
        "    multi_class=\"multinomial\",\n",
        "    solver=\"lbfgs\",\n",
        "    max_iter=1000\n",
        ")\n",
        "manual_model.fit(X_train, y_train)\n",
        "print(\"Manual Accuracy:\", manual_model.score(X_test, y_test))\n",
        "\n",
        "# Pipeline approach\n",
        "def create_vectorized_one_hot(options, attribute_to_index):\n",
        "    def transformer(X):\n",
        "        X = pd.DataFrame(X).iloc[:, 0]  # Convert input to Series\n",
        "        answers = [ans.split(\",\") for ans in X.astype(str)]\n",
        "        return vectorized_one_hot(answers, options, attribute_to_index)\n",
        "    return FunctionTransformer(transformer)\n",
        "\n",
        "def create_frequency_encoder(col):\n",
        "    def transformer(X):\n",
        "        X = pd.DataFrame(X).iloc[:, 0]  # Convert input to Series\n",
        "        return X.map(col.value_counts(normalize=True)).values.reshape(-1, 1)\n",
        "    return FunctionTransformer(transformer)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', ColumnTransformer([\n",
        "        ('num', StandardScaler(), [q1, q2, q4]),\n",
        "        ('q3', create_vectorized_one_hot(q3_options, q3_attribute_to_index), [q3]),\n",
        "        ('q7', create_vectorized_one_hot(q7_options, q7_attribute_to_index), [q7]),\n",
        "        ('q8', create_vectorized_one_hot(q8_options, q8_attribute_to_index), [q8]),\n",
        "        ('q5', create_frequency_encoder(df[q5]), [q5]),\n",
        "        ('q6', create_frequency_encoder(df[q6]), [q6])\n",
        "    ], remainder='drop')),\n",
        "    ('classifier', LogisticRegression(\n",
        "        multi_class='multinomial',\n",
        "        solver='lbfgs',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Fit pipeline\n",
        "pipeline.fit(df[questions], y)\n",
        "\n",
        "# Evaluate pipeline\n",
        "print(\"Pipeline Accuracy:\", pipeline.score(df[questions], y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keiWhaajAFi8",
        "outputId": "7842b804-78f8-4528-8e54-b564a7227c03"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Accuracy: 0.790273556231003\n",
            "Pipeline Accuracy: 0.8071776155717761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}